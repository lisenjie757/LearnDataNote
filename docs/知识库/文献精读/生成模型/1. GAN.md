#! https://zhuanlan.zhihu.com/p/655563877
# 1.【生成模型开山之作】GAN 论文精读

> 原文连接：[Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf)
> 源码连接：[http://www.github.com/goodfeli/adversarial](http://www.github.com/goodfeli/adversarial)

## 0. 核心总结

本文的核心是通过训练一组生成器-辨别器的对抗网络的思想去得到我们想要的生成网络，本文设计了一个精妙的损失函数和训练算法，使得生成器能最终能收敛到真实数据分布，辨别器能收敛到50%的辨别概率。

## 1. 摘要

GAN的框架包含两个模型：一个生成模型$G$和辨别模型$D$，通过同时训练这两个模型进行对抗， $G$的目标是通过捕获数据分布来使$D$犯错的概率最大，而$D$的目标是估计数据是来自于训练集而不是$G$。随着对抗训练的完成，$G$能够恢复训练集的分布且$D$的分辨概率为50%。

模型$G$和$D$都是由神经网络构建，并且通过反向传播来训练。

## 2. 对抗网络

GAN网络的目标通过数学的表示是：

- 生成模型$G$：输入一个噪声随机变量$p_z(z)$，最优化参数$\theta_g$，使得模型$G(z;\theta_g)$能够将输入映射到真实数据$\pmb{x}$
- 辨别模型$D$：输入一个数据$\pmb{x}$，最优化参数$\theta_d$，输出是真实数据的概率

于是可以构建如下损失函数$V(G,D)$来对两个参数进行最优化：
$$\min\limits_G \max\limits_D V(D,G)=\mathbb{E}_{\pmb{x}\sim p_{\text{data}(\pmb{x})}}[\log D(\pmb{x})]+\mathbb{E}_{z\sim p_z(z)}[\log (1-D(G(z)))]$$

根据以下公式，期望的梯度等于原梯度，所以可以使用梯度下降法来进行反向传播：
$$\lim\limits_{\sigma \to 0}\nabla_{\pmb{x}}\mathbb{E}_{\epsilon\sim N(0,\sigma \pmb{I})} f(\pmb{x}+\epsilon) = \nabla_{\pmb{x}}f(\pmb{x})$$

下图展示了一个GAN网络对抗训练的过程：
![image.png](https://cdn.nlark.com/yuque/0/2023/png/34751784/1693826120208-889784b6-3ec1-41d0-b969-67797bc5809d.png#averageHue=%23f5f4f4&clientId=ub8497ee9-ff3c-4&from=paste&height=235&id=ub63ab1fa&originHeight=294&originWidth=955&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=49949&status=done&style=none&taskId=u3f6756c1-a85d-47ea-829f-908c1d07539&title=&width=764)

其中，蓝色虚线表示判别模型的分布$D$，黑色虚线表示数据真实分布$p_{\text{data}}(x)$，绿色实现表示生成分布$p_g(x)$。两条水平线表示被采样的区域，$z$是被均匀采样的，向上的箭头表示$x=G(z)$的映射。

- （a）： $p_g$近似$p_\text{data}$，$D$开始只能部分辨别准确
- （b）：在算法内循环中，先最优化训练$D$，$D$的最优解为：$D^*(x)=\frac {p_{\text{data}}(x)} {p_{\text{data}}(x)+p_g(x)}$
- （c）：在训练完$D$后，$D$的梯度会引导训练$G(z)$更接近真实分布
- （d）：最终如果训练收敛，则$p_g(x) = p_{\text{data}}(x)$，$D(X)=\frac 12$

GAN网络训练算法的伪代码如下：

> for iterations do
>> for $k$ steps do
>> - 从$p_z(z)$中采样$m$个minibatch噪声$\{z^{(1)}, \ldots ,z^{(m)}\}$
>> - 从$p_{\text{data}}(x)$中采样$m$个minibatch真实分布$\{x^{(1)}, \ldots ,x^{(m)}\}$
>> - 通过随机梯度下降算法更新辨别器：
>> $$\nabla_{\theta_d} \frac 1m \sum^m_{i=1} [\log D(x^{(i)})+\log (1-D(G(z^{(i)})))]$$
>> end for
> - 从$p_z(z)$中采样$m$个minibatch噪声$\{z^{(1)}, \ldots ,z^{(m)}\}$
> - 通过随机梯度下降算法更新生成器：
> $$\nabla_{\theta_g} \frac 1m \sum^m_{i=1} \log(1-D(G(z^{(i)})))$$
> end for
> 
> 梯度下降算法可以使用任意基于梯度的学习算法，本文使用了Momentum。

其中，$k$为超参数。$k$的设置很重要，若$k$较小则辨别器$D$变化较小导致生成器$G$也变化较小；若$k$较大则辨别器$D$辨别能力很强导致$D(G(Z))$的梯度接近于0，也影响$G$的更新。

## 3. 理论证明

已知我们的目标是使生成数据等于真实数据，辨别器的分辨概率为50%。此节通过理论证明本文设计的损失函数的合理性，为什么通过最优化该损失函数可以收敛至 $p_g(x) = p_{\text{data}}(x)$，$D(X)=\frac 12$。

**命题1.** 对于给定的$G$，最优的辨别器$D$是：
$$D^*_G(x)=\frac {p_{\text{data}}(x)} {p_{\text{data}}(x)+p_g(x)}$$

证明：辨别器$D$训练的准则是，对于任意给定的$G$，令$V(G,D)$最大。将损失函数展开，得：
$$\begin{aligned} 
V(G,D) &= \int_x p_{\text{data}}(x) \log (D(x))dx + \int_z p_z(z) \log(1-D(G(z)))dz \\
&= \int_x p_{\text{data}}(x) \log (D(x)) + p_g(x) \log(1-D(x))dx
\end{aligned}$$

现要求$V(G,D)$关于$D$的最大值，则固定$G$求$D$的偏导，得：
$$\begin{aligned} 
&\frac {\partial}{\partial D(x)} (p_{\text{data}}(x) \log (D(x)) + p_g(x) \log(1-D(x))) \\
&= \frac {p_{\text{data}}(x)}{D(x)} - \frac {p_g(x)}{1-D(x)} = 0, \quad D(x) \in [0,1] \\
&\Rightarrow D^*(x)=\frac {p_{\text{data}}(x)} {p_{\text{data}}(x)+p_g(x)}
\end{aligned}$$

根据命题1的结果，损失函数可以重新表示为：
$$\begin{aligned} 
C(G) &= \max_D V(G,D) \\
&= \mathbb{E}_{x\sim p_{\text{data}}}[\log D^*_G(x)]+\mathbb{E}_{z\sim p_z}[\log (1-D^*_G(G(z)))] \\
&= \mathbb{E}_{x\sim p_{\text{data}}}[\log D^*_G(x)]+\mathbb{E}_{x\sim p_g}[\log (1-D^*_G(x))] \\
&= \mathbb{E}_{x\sim p_{\text{data}}}[\log \frac {p_{\text{data}}(x)} {p_{\text{data}}(x)+p_g(x)}]+\mathbb{E}_{x\sim p_g}[\log \frac {p_g(x)} {p_{\text{data}}(x)+p_g(x)}]
\end{aligned}$$

**定理1.** 当且仅当 $p_g(x) = p_{\text{data}}(x)$时，$C(G)$达到全局最小值，最小值为$-\log 4$。
证明：对$C(G)$做如下变换：
$$\begin{aligned} 
C(G) &= \int_x p_{\text{data}}(x) \log \frac {p_{\text{data}}(x)} {p_{\text{data}}(x)+p_g(x)} + p_g(x) \log \frac {p_g(x)} {p_{\text{data}}(x)+p_g(x)} dx \\ 
&= \int_x p_{\text{data}}(x) \log \frac{\frac{p_{\text{data}}(x)}2}{\frac{p_{\text{data}}(x)+p_g(x)}2} + p_g(x) \log \frac{\frac{p_g(x)}2}{\frac{p_{\text{data}}(x)+p_g(x)}2} dx \\
&= -\log4 + \int_x p_{\text{data}}(x) \log \frac{p_{\text{data}}(x)}{\frac{p_{\text{data}}(x)+p_g(x)}2} + p_g(x) \log \frac{p_g(x)}{\frac{p_{\text{data}}(x)+p_g(x)}2} dx \\
&= -\log4 + KL(p_{\text{data}} \parallel \frac{p_{\text{data}}+p_g}2) + KL(p_g \parallel \frac{p_{\text{data}}+p_g}2) \\
&= -\log4 + 2 \cdot JS(p_{\text{data}} \parallel p_g) 
\end{aligned}$$

根据JS散度的非负性，$JS(p_{\text{data}} \parallel p_g) \geq 0$，且当且仅当$p_g = p_{\text{data}}$时，$JS(p_{\text{data}} \parallel p_g) = 0$，因此$C(G)$有最小值$-\log 4$。

> 如果不了解KL和JS散度，可以阅读我的这篇文章：[信息量和熵](https://lisenjie757.github.io/%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E4%BF%A1%E6%81%AF%E9%87%8F%E5%92%8C%E7%86%B5.html)

**定理2.** 当$G$和$D$有足够容量的时候，且在训练算法中$D$可以达到其最优解，如果对$p_g$的优化是按照如下公式，那么$p_g$最终可以收敛到$p_{\text{data}}$
$$\mathbb{E}_{x\sim p_{\text{data}}}[\log D^*_G(x)]+\mathbb{E}_{x\sim p_g}[\log (1-D^*_G(x))]$$

证明：把$V(G,D) = U(p_g,D)$看成是一个关于$p_g$的函数，且是凸函数，由于一个凸函数的积分上限函数还是凸函数，所以对凸函数做梯度下降时会得到一个最优解。

实际上，训练算法每次迭代并没有对$D$优化到极致，只是迭代了$k$步，但实践中训练算法的表现效果很好。