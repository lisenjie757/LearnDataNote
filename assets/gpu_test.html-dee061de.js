const n=JSON.parse(`{"key":"v-a6c3095a","path":"/%E7%9F%A5%E8%AF%86%E5%BA%93/PyTorch%E5%85%A5%E9%97%A8/gpu_test.html","title":"lesson0. GPU性能测试","lang":"zh-CN","frontmatter":{"description":"lesson0. GPU性能测试 import torch import time print(torch.__version__) # 返回pytorch的版本 print(torch.cuda.is_available()) # 当CUDA可用时返回True a = torch.randn(10000, 1000) # 返回10000行1000列的张量矩阵 b = torch.randn(1000, 2000) # 返回1000行2000列的张量矩阵 t0 = time.time() # 记录时间 c = torch.matmul(a, b) # 矩阵乘法运算 t1 = time.time() # 记录时间 print(a.device, t1 - t0, c.norm(2)) # c.norm(2)表示矩阵c的二范数 device = torch.device('cuda') # 用GPU来运行 a = a.to(device) b = b.to(device) # 初次调用GPU，需要数据传送，因此比较慢 t0 = time.time() c = torch.matmul(a, b) t2 = time.time() print(a.device, t2 - t0, c.norm(2)) # 这才是GPU处理数据的真实运行时间，当数据量越大，GPU的优势越明显 t0 = time.time() c = torch.matmul(a, b) t2 = time.time() print(a.device, t2 - t0, c.norm(2))","head":[["meta",{"property":"og:url","content":"https://lisenjie757.github.io/%E7%9F%A5%E8%AF%86%E5%BA%93/PyTorch%E5%85%A5%E9%97%A8/gpu_test.html"}],["meta",{"property":"og:site_name","content":"Li Senjie"}],["meta",{"property":"og:title","content":"lesson0. GPU性能测试"}],["meta",{"property":"og:description","content":"lesson0. GPU性能测试 import torch import time print(torch.__version__) # 返回pytorch的版本 print(torch.cuda.is_available()) # 当CUDA可用时返回True a = torch.randn(10000, 1000) # 返回10000行1000列的张量矩阵 b = torch.randn(1000, 2000) # 返回1000行2000列的张量矩阵 t0 = time.time() # 记录时间 c = torch.matmul(a, b) # 矩阵乘法运算 t1 = time.time() # 记录时间 print(a.device, t1 - t0, c.norm(2)) # c.norm(2)表示矩阵c的二范数 device = torch.device('cuda') # 用GPU来运行 a = a.to(device) b = b.to(device) # 初次调用GPU，需要数据传送，因此比较慢 t0 = time.time() c = torch.matmul(a, b) t2 = time.time() print(a.device, t2 - t0, c.norm(2)) # 这才是GPU处理数据的真实运行时间，当数据量越大，GPU的优势越明显 t0 = time.time() c = torch.matmul(a, b) t2 = time.time() print(a.device, t2 - t0, c.norm(2))"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-04-26T11:51:50.000Z"}],["meta",{"property":"article:author","content":"李森杰"}],["meta",{"property":"article:modified_time","content":"2023-04-26T11:51:50.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"lesson0. GPU性能测试\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-04-26T11:51:50.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"李森杰\\",\\"url\\":\\"https://lisenjie757.github.io\\"}]}"]]},"headers":[],"git":{"createdTime":1682509910000,"updatedTime":1682509910000,"contributors":[{"name":"lisenjie757","email":"1215954303@qq.com","commits":1}]},"readingTime":{"minutes":0.67,"words":202},"filePathRelative":"知识库/PyTorch入门/gpu_test.md","localizedDate":"2023年4月26日","excerpt":"<h1> lesson0. GPU性能测试</h1>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> torch\\n<span class=\\"token keyword\\">import</span> time\\n\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span>torch<span class=\\"token punctuation\\">.</span>__version__<span class=\\"token punctuation\\">)</span>        <span class=\\"token comment\\"># 返回pytorch的版本</span>\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span>torch<span class=\\"token punctuation\\">.</span>cuda<span class=\\"token punctuation\\">.</span>is_available<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>        <span class=\\"token comment\\"># 当CUDA可用时返回True</span>\\n\\na <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>randn<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">10000</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1000</span><span class=\\"token punctuation\\">)</span>    <span class=\\"token comment\\"># 返回10000行1000列的张量矩阵</span>\\nb <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>randn<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">1000</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">2000</span><span class=\\"token punctuation\\">)</span>     <span class=\\"token comment\\"># 返回1000行2000列的张量矩阵</span>\\n\\nt0 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>        <span class=\\"token comment\\"># 记录时间</span>\\nc <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">,</span> b<span class=\\"token punctuation\\">)</span>      <span class=\\"token comment\\"># 矩阵乘法运算</span>\\nt1 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>        <span class=\\"token comment\\"># 记录时间</span>\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">.</span>device<span class=\\"token punctuation\\">,</span> t1 <span class=\\"token operator\\">-</span> t0<span class=\\"token punctuation\\">,</span> c<span class=\\"token punctuation\\">.</span>norm<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>     <span class=\\"token comment\\"># c.norm(2)表示矩阵c的二范数</span>\\n\\ndevice <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>device<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'cuda'</span><span class=\\"token punctuation\\">)</span>       <span class=\\"token comment\\"># 用GPU来运行</span>\\na <span class=\\"token operator\\">=</span> a<span class=\\"token punctuation\\">.</span>to<span class=\\"token punctuation\\">(</span>device<span class=\\"token punctuation\\">)</span>\\nb <span class=\\"token operator\\">=</span> b<span class=\\"token punctuation\\">.</span>to<span class=\\"token punctuation\\">(</span>device<span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 初次调用GPU，需要数据传送，因此比较慢</span>\\nt0 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\nc <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">,</span> b<span class=\\"token punctuation\\">)</span>\\nt2 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">.</span>device<span class=\\"token punctuation\\">,</span> t2 <span class=\\"token operator\\">-</span> t0<span class=\\"token punctuation\\">,</span> c<span class=\\"token punctuation\\">.</span>norm<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 这才是GPU处理数据的真实运行时间，当数据量越大，GPU的优势越明显</span>\\nt0 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\nc <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">,</span> b<span class=\\"token punctuation\\">)</span>\\nt2 <span class=\\"token operator\\">=</span> time<span class=\\"token punctuation\\">.</span>time<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span>a<span class=\\"token punctuation\\">.</span>device<span class=\\"token punctuation\\">,</span> t2 <span class=\\"token operator\\">-</span> t0<span class=\\"token punctuation\\">,</span> c<span class=\\"token punctuation\\">.</span>norm<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{n as data};
