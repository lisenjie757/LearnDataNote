const n=JSON.parse('{"key":"v-23f3dc59","path":"/%E7%9F%A5%E8%AF%86%E5%BA%93/PyTorch%E5%85%A5%E9%97%A8/lesson5_autograd.html","title":"lesson5. 自动求导机制","lang":"zh-CN","frontmatter":{"description":"lesson5. 自动求导机制 import torch 定义最简单的单层神经网络 ## input tensor x = torch.ones(5) ## expected output y = torch.zeros(3) w = torch.randn(5,3,requires_grad=True) b = torch.randn(3,requires_grad=True) z = torch.matmul(x,w) + b loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)","head":[["meta",{"property":"og:url","content":"https://lisenjie757.github.io/%E7%9F%A5%E8%AF%86%E5%BA%93/PyTorch%E5%85%A5%E9%97%A8/lesson5_autograd.html"}],["meta",{"property":"og:site_name","content":"Li Senjie"}],["meta",{"property":"og:title","content":"lesson5. 自动求导机制"}],["meta",{"property":"og:description","content":"lesson5. 自动求导机制 import torch 定义最简单的单层神经网络 ## input tensor x = torch.ones(5) ## expected output y = torch.zeros(3) w = torch.randn(5,3,requires_grad=True) b = torch.randn(3,requires_grad=True) z = torch.matmul(x,w) + b loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-04-26T11:51:50.000Z"}],["meta",{"property":"article:author","content":"李森杰"}],["meta",{"property":"article:modified_time","content":"2023-04-26T11:51:50.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"lesson5. 自动求导机制\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-04-26T11:51:50.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"李森杰\\",\\"url\\":\\"https://lisenjie757.github.io\\"}]}"]]},"headers":[{"level":2,"title":"定义最简单的单层神经网络","slug":"定义最简单的单层神经网络","link":"#定义最简单的单层神经网络","children":[]},{"level":2,"title":"反向传播函数的引用存储在张量的grad_fn属性中","slug":"反向传播函数的引用存储在张量的grad-fn属性中","link":"#反向传播函数的引用存储在张量的grad-fn属性中","children":[]},{"level":2,"title":"计算梯度","slug":"计算梯度","link":"#计算梯度","children":[]},{"level":2,"title":"禁用梯度跟踪","slug":"禁用梯度跟踪","link":"#禁用梯度跟踪","children":[]},{"level":2,"title":"张量梯度和Jacobian Products","slug":"张量梯度和jacobian-products","link":"#张量梯度和jacobian-products","children":[]}],"git":{"createdTime":1682509910000,"updatedTime":1682509910000,"contributors":[{"name":"lisenjie757","email":"1215954303@qq.com","commits":1}]},"readingTime":{"minutes":1.43,"words":430},"filePathRelative":"知识库/PyTorch入门/lesson5_autograd.md","localizedDate":"2023年4月26日","excerpt":"<h1> lesson5. 自动求导机制</h1>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> torch\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div></div></div><h2> 定义最简单的单层神经网络</h2>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token comment\\">## input tensor</span>\\nx <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>ones<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">5</span><span class=\\"token punctuation\\">)</span>\\n<span class=\\"token comment\\">## expected output</span>\\ny <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>zeros<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">3</span><span class=\\"token punctuation\\">)</span>\\nw <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>randn<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">5</span><span class=\\"token punctuation\\">,</span><span class=\\"token number\\">3</span><span class=\\"token punctuation\\">,</span>requires_grad<span class=\\"token operator\\">=</span><span class=\\"token boolean\\">True</span><span class=\\"token punctuation\\">)</span>\\nb <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>randn<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">3</span><span class=\\"token punctuation\\">,</span>requires_grad<span class=\\"token operator\\">=</span><span class=\\"token boolean\\">True</span><span class=\\"token punctuation\\">)</span>\\nz <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">,</span>w<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> b\\nloss <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>nn<span class=\\"token punctuation\\">.</span>functional<span class=\\"token punctuation\\">.</span>binary_cross_entropy_with_logits<span class=\\"token punctuation\\">(</span>z<span class=\\"token punctuation\\">,</span>y<span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}');export{n as data};
