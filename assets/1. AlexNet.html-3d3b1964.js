import{_ as l,Y as n,Z as r,$ as a,a0 as e,a1 as s,a2 as t,D as o}from"./framework-d3f694d0.js";const p={},c=a("h1",{id:"_1-【经典网络】alexnet-论文精读",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#_1-【经典网络】alexnet-论文精读","aria-hidden":"true"},"#"),e(" 1.【经典网络】AlexNet 论文精读")],-1),h={href:"https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf",target:"_blank",rel:"noopener noreferrer"},d=t('<h2 id="_0-核心总结" tabindex="-1"><a class="header-anchor" href="#_0-核心总结" aria-hidden="true">#</a> 0. 核心总结</h2><p>核心是提出了一种深层卷积神经网络的架构，并引入了GPU训练、ReLU激活函数、Dropout正则化这些训练深层卷积神经网络的手段。</p><h2 id="_1-摘要" tabindex="-1"><a class="header-anchor" href="#_1-摘要" aria-hidden="true">#</a> 1. 摘要</h2><p>训练了一个大型的卷积神经网络，在ImageNet LSVRC-2010和ILSVRC-2012图像分类竞赛中取得了远低于第二名错误率的成绩。</p><h2 id="_2-引言" tabindex="-1"><a class="header-anchor" href="#_2-引言" aria-hidden="true">#</a> 2. 引言</h2><p>事实证明，大图像数据集比小图像数据集能够训练更优的模型，但同时对于ImageNet这样的超大型数据集也需要与之对应的具有强大学习能力的模型，CNN对图像的性质（局部平稳和参数共享）使其比相同性能的标准前馈神经网络参数量要少得多。</p><p>尽管CNN具有如此优秀的性质，但计算它还是很昂贵的，然而得益于GPU使得训练大型的CNN网络成为了可能，并且大型图像数据集ImageNet的出现使得模型不会出现严重的过拟合。</p><p>本文的具体贡献如下：</p><ol><li>在ImageNet子集上训练了迄今为止最大的卷积神经网络，并取得了迄今为止最好的成绩；</li><li>编写了一个高度优化的2D卷积的GPU实现，以及提供了训练卷积神经网络的所有操作细节，包括如何提高性能、减少训练时间等；</li><li>即使有大量的数据，但由于网络的太大还是会有过拟合的问题，所以采用了几种有效的技术来防止过拟合。</li></ol><h2 id="_3-数据集" tabindex="-1"><a class="header-anchor" href="#_3-数据集" aria-hidden="true">#</a> 3. 数据集</h2><p>使用了著名的ImageNet数据集，介绍直接从原文翻译。</p><blockquote><p>ImageNet是一个由超过1500万张标注的高分辨率图像组成的数据集，属于大约22，000个类别。这些图像是从网上收集的，并由人类贴标者使用亚马逊的研究工具众包工具进行标记。从2010年开始，作为Pascal视觉对象挑战赛的一部分，每年举办一次名为ImageNet大规模视觉识别挑战赛( ILSVRC )的竞赛。ILSVRC使用ImageNet的一个子集，在1000个类别中的每个类别中大约有1000个图像。总共有大约120万张训练图像、50,000张验证图像和150,000张测试图像。<br> ILSVRC-2010是唯一一个测试集标签可用的ILSVRC版本，因此这是我们进行大部分实验的版本。由于我们也在ILSVRC-2012竞赛中输入了我们的模型，在第6节中我们也报告了我们在这个版本的数据集上的结果，对于这个版本的数据集，测试集标签是不可用的。在ImageNet上，通常报告两个错误率：top-1和top-5，其中top-5错误率是模型认为最可能的5个标签中没有正确标签的测试图像的分数。<br> ImageNet由可变分辨率的图像组成，而我们的系统需要一个恒定的输入维度。因此，我们将图像降采样到256×256的固定分辨率。给定一个矩形图像，我们首先对图像进行缩放，使较短的边长为256，然后从结果图像中裁剪出中心的256×256块。我们没有以任何其他方式预处理图像，除了从每个像素中减去训练集的平均活动。因此，我们在像素的(中心)原始RGB值上训练我们的网络。</p></blockquote><h2 id="_4-架构" tabindex="-1"><a class="header-anchor" href="#_4-架构" aria-hidden="true">#</a> 4. 架构</h2><p>AlexNet的网络架构如下图所示，它包含5个卷积层和3个全连接层，下面会介绍AlexNet网络一些新颖的特征，以下特征根据重要性向下排序。</p><figure><img src="https://i.imgur.com/5F8HDJg.png" alt="AlexNet网络架构图" tabindex="0" loading="lazy"><figcaption>AlexNet网络架构图</figcaption></figure><h3 id="_4-1-relu激活函数" tabindex="-1"><a class="header-anchor" href="#_4-1-relu激活函数" aria-hidden="true">#</a> 4.1 ReLU激活函数</h3><p>ReLU激活函数的公式：</p>',17),m=a("p",{class:"katex-block"},[a("span",{class:"katex-display"},[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[a("semantics",null,[a("mrow",null,[a("mi",null,"f"),a("mo",{stretchy:"false"},"("),a("mi",null,"x"),a("mo",{stretchy:"false"},")"),a("mo",null,"="),a("mi",null,"m"),a("mi",null,"a"),a("mi",null,"x"),a("mo",{stretchy:"false"},"("),a("mn",null,"0"),a("mo",{separator:"true"},","),a("mi",null,"x"),a("mo",{stretchy:"false"},")")]),a("annotation",{encoding:"application/x-tex"}," f(x) = max(0,x) ")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),a("span",{class:"mopen"},"("),a("span",{class:"mord mathnormal"},"x"),a("span",{class:"mclose"},")"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"="),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord mathnormal"},"ma"),a("span",{class:"mord mathnormal"},"x"),a("span",{class:"mopen"},"("),a("span",{class:"mord"},"0"),a("span",{class:"mpunct"},","),a("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),a("span",{class:"mord mathnormal"},"x"),a("span",{class:"mclose"},")")])])])])],-1),g=t('<p>本文通过大量实验证明使用ReLU作为激活函数比使用tanh作激活函数训练速度要快好几倍，如下图所示：</p><figure><img src="https://i.imgur.com/uotVyNs.png" alt="relu与tanh速度对比图" tabindex="0" loading="lazy"><figcaption>relu与tanh速度对比图</figcaption></figure><h3 id="_4-2-多gpu训练" tabindex="-1"><a class="header-anchor" href="#_4-2-多gpu训练" aria-hidden="true">#</a> 4.2 多GPU训练</h3><p>本文使用两块GTX 580 GPU来训练AlexNet，采用并行化方案，每个GPU上放置一半的内核。</p><h3 id="_4-3-局部响应归一化-lrn-local-response-normalization" tabindex="-1"><a class="header-anchor" href="#_4-3-局部响应归一化-lrn-local-response-normalization" aria-hidden="true">#</a> 4.3 局部响应归一化（LRN，Local Response Normalization）</h3><p>一种提高泛化性的手段，现在已不常用，被批归一化Batch Normalization代替。</p><h3 id="_4-4-重叠池化-overlapping-pooling" tabindex="-1"><a class="header-anchor" href="#_4-4-重叠池化-overlapping-pooling" aria-hidden="true">#</a> 4.4 重叠池化（Overlapping Pooling）</h3><p>即步长要小于池化单元的大小，使得每一个池化单元组成的网格有所重叠，这样能稍微降低点错误率。</p><h3 id="_4-5-整体架构" tabindex="-1"><a class="header-anchor" href="#_4-5-整体架构" aria-hidden="true">#</a> 4.5 整体架构</h3><p>AlexNet包含8个带权重的层，前5个为卷积层，其余3个为全连接层，最后输出到一个1000类的Softmax层。</p><p>第2层，第4层，第5层卷积层内核仅连接到位于同一GPU上的前一层内核。第3层内核连接到第二层的所有内核，全连接层也与上一层的所有神经元相连。局部相应归一化应用于第1层和第2层，最大池化层是重叠池化，使用在第1层，第2层和第5层。</p><h2 id="_5-减少过拟合" tabindex="-1"><a class="header-anchor" href="#_5-减少过拟合" aria-hidden="true">#</a> 5. 减少过拟合</h2><p>第一种方式是使用数据增强，包括以下两种形式：</p><ol><li>通过图像平移和水平反射生成图像；</li><li>改变训练图像中RGB通道的强度，即对整个ImageNet训练集的RGB像素值集合进行PCA主成分分析，将权重加到对应的RGB通道上。</li></ol><p>第二种方式是使用Dropout方法，即在每轮前向传播和反向传播中，每层的神经元将会有一定的比例“失活”，即在本轮置为0，不参与前向传播和反向传播的过程。</p><h2 id="_6-训练细节" tabindex="-1"><a class="header-anchor" href="#_6-训练细节" aria-hidden="true">#</a> 6. 训练细节</h2><p>优化器为SGD，batch size为128，momentum为0.9，权重衰减（L2正则）为5e-4。</p><p>从一个均值为0，标准差为0.01的高斯分布中初始化各层权重，用常数1初始化第2层，第4层，第5层和全连接层的偏置，用常数0初始化其余层的偏置。</p><p>每层的学习率相同，并在训练过程中手动调整。学习率初始化为0.01，当验证集错误率停止下降时，将学习率减小10倍继续训练，在终止训练前减小3次。</p><p>本文在120万张图像训练集上训练了90个epoch，在两个NVDIA GTX 580 3GB GPU上训练了5～6天的时间。</p><h2 id="_7-结果" tabindex="-1"><a class="header-anchor" href="#_7-结果" aria-hidden="true">#</a> 7. 结果</h2><p>在ILSVRC-2010测试集上与其它方法的对比结果：</p><figure><img src="https://i.imgur.com/9ZvQf02.png" alt="AlexNet测试结果图1" tabindex="0" loading="lazy"><figcaption>AlexNet测试结果图1</figcaption></figure><p>在ILSVRC-2012验证集和测试集上的对比结果，*号表示在完整版ImageNet数据集上进行过预训练再微调，1 CNN表示一个标准的AlexNet，5 CNN表示训练5个AlexNet将预测结果取平均，7 CNN表示在AlexNet最后一个池化层后再加上第6个卷积层：</p><figure><img src="https://i.imgur.com/A8guPdw.png" alt="AlexNet测试结果图2" tabindex="0" loading="lazy"><figcaption>AlexNet测试结果图2</figcaption></figure><p>下图展示了第1层卷积层的96个卷积核的可视化情况，表征了卷积核所学习到的特征：</p><figure><img src="https://i.imgur.com/f3WtVFM.png" alt="AlexNet卷积核可视化" tabindex="0" loading="lazy"><figcaption>AlexNet卷积核可视化</figcaption></figure><p>下图展示了AlexNet在8张测试图像上的top-5预测结果，可以发现即使是偏离中心的对象（如第1幅图）也可以被网络识别，并且大多数图像top-5预测结果尽管并非完全正确但似乎也是合理的，同时也可以注意到部分图像（如第7幅图）本身就具有模糊性：</p><figure><img src="https://i.imgur.com/2OnlTqo.png" alt="AlexNet图像预测" tabindex="0" loading="lazy"><figcaption>AlexNet图像预测</figcaption></figure><p>下图展示了在AlexNet最后一个隐藏层的特征向量欧氏距离最小的几幅图像（每行），可以发现特征向量欧式距离相近的图片确实表征的是同一个对象，即使对象的位置、朝向、明暗不同，这表明卷积神经网络可以很好的提取出图像的语义特征</p><figure><img src="https://i.imgur.com/9ivEjgY.jpg" alt="AlexNet最后一个隐藏层所表征的特征向量" tabindex="0" loading="lazy"><figcaption>AlexNet最后一个隐藏层所表征的特征向量</figcaption></figure><h2 id="_8-思考" tabindex="-1"><a class="header-anchor" href="#_8-思考" aria-hidden="true">#</a> 8. 思考</h2><p>本文认为卷积神经网络的深度是很重要的，减小深度会导致性能的下降。</p><p>AlexNet虽然在图像分类任务上取得了很大的提升，但对比人类视觉系统的识别还是有一定差距的。</p>',34);function u(x,f){const i=o("ExternalLinkIcon");return n(),r("div",null,[c,a("blockquote",null,[a("p",null,[e("原文链接："),a("a",h,[e("ImageNet Classification with Deep Convolutional Neural Networks"),s(i)])])]),d,m,g])}const _=l(p,[["render",u],["__file","1. AlexNet.html.vue"]]);export{_ as default};
